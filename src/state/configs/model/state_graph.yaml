# STATE/state/src/state/configs/model/state_graph.yaml
name: state_graph
checkpoint: null
device: mps

kwargs:
  # Inherit from state_sm
  cell_set_len: 128
  blur: 0.05
  hidden_dim: 672
  loss: energy
  confidence_head: False
  n_encoder_layers: 4
  n_decoder_layers: 4
  predict_residual: True
  softplus: True
  freeze_pert: False
  transformer_decoder: False
  finetune_vci_decoder: False
  residual_decoder: False
  batch_encoder: False
  nb_decoder: False
  mask_attn: False
  use_effect_gating_token: False
  use_basal_projection: False
  distributional_loss: energy
  gene_decoder_bool: False
  init_from: null
  transformer_backbone_key: llama
  transformer_backbone_kwargs:
      max_position_embeddings: ${model.kwargs.cell_set_len}
      hidden_size: ${model.kwargs.hidden_dim}
      intermediate_size: 2688
      num_hidden_layers: 4
      num_attention_heads: 8
      num_key_value_heads: 8
      head_dim: 84
      use_cache: false
      attention_dropout: 0.0
      hidden_dropout: 0.0
      layer_norm_eps: 1e-6
      pad_token_id: 0
      bos_token_id: 1
      eos_token_id: 2
      tie_word_embeddings: false
      rotary_dim: 0
      use_rotary_embeddings: false
  
  # Graph-specific parameters
  use_graph_embeddings: true
  gnn_backend: basic_gnn  # ‚Üê Options: basic_gnn, exphormer, multi_graph
  
  # Graph configuration - supported graph types
  graph_config:
    go_graph:
      type: "go"
      args:
        reduce2perts: true
        norm_weights: false
        mode: "top_20"
    string_graph:
      type: "string"
      args:
        reduce2perts: true
        norm_weights: false
        mode: "top_20"
    reactome_graph:
      type: "reactome"
      args:
        reduce2perts: true
        norm_weights: false
        mode: "top_20"
    
  
  graph_cache_dir: "graphs"